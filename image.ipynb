{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1f7225f-88a0-46f3-a015-7d6ec7a3c65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.4)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.10.1-cp313-cp313-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pillow in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (11.1.0)\n",
      "Requirement already satisfied: torch in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.6.0)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.21.0-cp313-cp313-win_amd64.whl.metadata (6.3 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.1-cp313-cp313-win_amd64.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: filelock in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (4.13.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (78.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\abhis\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Using cached matplotlib-3.10.1-cp313-cp313-win_amd64.whl (8.1 MB)\n",
      "Using cached torchvision-0.21.0-cp313-cp313-win_amd64.whl (1.6 MB)\n",
      "Using cached contourpy-1.3.1-cp313-cp313-win_amd64.whl (220 kB)\n",
      "Installing collected packages: contourpy, matplotlib, torchvision\n",
      "Successfully installed contourpy-1.3.1 matplotlib-3.10.1 torchvision-0.21.0\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy matplotlib pillow torch torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ab7fe4-31a8-4c44-b180-0e81887ed1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training for technique: original\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import Required Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Step 2: Define Image Processing Techniques\n",
    "def apply_image_processing(image, technique):\n",
    "    if technique == \"original\":\n",
    "        return image\n",
    "    elif technique == \"sharpen\":\n",
    "        return image.filter(ImageFilter.SHARPEN)\n",
    "    elif technique == \"contrast\":\n",
    "        enhancer = ImageEnhance.Contrast(image)\n",
    "        return enhancer.enhance(2.0)\n",
    "    elif technique == \"blur\":\n",
    "        return image.filter(ImageFilter.GaussianBlur(radius=2))\n",
    "    elif technique == \"edge\":\n",
    "        return image.filter(ImageFilter.FIND_EDGES)\n",
    "\n",
    "# Step 3: Create Custom Dataset with Processing\n",
    "class ProcessedImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_dir, transform=None, technique='original'):\n",
    "        self.dataset = datasets.ImageFolder(root=root_dir)\n",
    "        self.transform = transform\n",
    "        self.technique = technique\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.dataset.samples[idx]\n",
    "        image = Image.open(path).convert(\"RGB\")\n",
    "        image = apply_image_processing(image, self.technique)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Step 4: Transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Path to data (Update accordingly)\n",
    "data_path = r\"C:\\Users\\abhis\\OneDrive\\Desktop\\image processing project\\Plant Leaf Disease Detection Using Deep Learning - A Multi-Dataset Approach (Web sourced Dataset)\"\n",
    "\n",
    "\n",
    "# Step 5: Load Data\n",
    "techniques = ['original', 'sharpen', 'contrast', 'blur', 'edge']\n",
    "datasets_dict = {\n",
    "    tech: ProcessedImageDataset(os.path.join(data_path, \"train\"), transform=transform, technique=tech)\n",
    "    for tech in techniques\n",
    "}\n",
    "test_dataset = ProcessedImageDataset(os.path.join(data_path, \"test\"), transform=transform, technique='original')\n",
    "\n",
    "# Step 6: Simple CNN Model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=16):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*32*32, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Step 7: Training & Evaluation\n",
    "def train_and_evaluate(train_data, test_data, technique):\n",
    "    print(f\"\\nTraining for technique: {technique}\")\n",
    "    model = SimpleCNN(num_classes=16).to(device)\n",
    "    train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "    test_loader = DataLoader(test_data, batch_size=16)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(5):  # reduce for fast testing\n",
    "        model.train()\n",
    "        running_loss = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "    # Evaluate\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    acc = 100 * correct / total\n",
    "    print(f\"Test Accuracy for {technique}: {acc:.2f}%\")\n",
    "    return acc\n",
    "\n",
    "# Step 8: Run for All Techniques\n",
    "results = {}\n",
    "for tech in techniques:\n",
    "    acc = train_and_evaluate(datasets_dict[tech], test_dataset, tech)\n",
    "    results[tech] = acc\n",
    "\n",
    "# Step 9: Visualize Results\n",
    "plt.bar(results.keys(), results.values(), color='skyblue')\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.title(\"Accuracy Comparison Across Image Processing Techniques\")\n",
    "plt.xticks(rotation=30)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20560ce5-a7f1-4071-aeaa-5e7143b1f98c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
